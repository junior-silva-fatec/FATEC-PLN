{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4MulTIWrRrJyCMxeu/j5U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Aula 06 - Análise Semântica"],"metadata":{"id":"ov_LslBCA-9g"}},{"cell_type":"markdown","source":["## Exemplo 01 - Representação do significado das palavras e frases com redes Semânticas"],"metadata":{"id":"y-roG_NgBGid"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zixjmB0257Yo","executionInfo":{"status":"ok","timestamp":1744294048114,"user_tz":180,"elapsed":9068,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"521b4fed-32b7-46be-81b6-0df5f75098fe"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["[Synset('beach_wagon.n.01'), Synset('car.n.01'), Synset('car.n.02'), Synset('cart.n.01')]\n","beach_wagon\n","car\n","car\n","cart\n"]}],"source":["import nltk\n","from nltk.corpus import wordnet\n","\n","nltk.download ('wordnet')\n","# banco de dados para utilização do sinônimos\n","nltk.download('omw-1.4')\n","# Corpus que relaciona as palavras em diversos idiomas - tradução automática\n","\n","# Método para encontrar os sinônimos da palavras indicada e o idioma\n","sinonimos = wordnet. synsets(\"carro\", lang=\"por\")\n","\n","print(sinonimos) # imprimi a lista gerada\n","for s in sinonimos:\n","  print(s.lemmas ()[0].name()) # Mostra sinônimos da palavra\n","  # s. lemmas(): Obtém a lista de lemmas (formas básicas das palavras) no synset atual.\n","  # [0]: Pega o primeiro lemma da lista.\n","  # .name(): Obtém o nome do lemma (o sinônimo em si).\n","  # print(): Imprime o sinônimo na tela."]},{"cell_type":"markdown","source":["## Exemplo 02 - Representação do significado das palavras e frases por Vetores (embeddings)."],"metadata":{"id":"iKwBSUodCEiV"}},{"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download pt_core_news_md"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTvRGx_KEvnM","executionInfo":{"status":"ok","timestamp":1744295099178,"user_tz":180,"elapsed":11056,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"c9c8f5a6-f8ca-400f-af60-8fe3c4d05fd8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n","Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Collecting pt-core-news-md==3.8.0\n","  Using cached https://github.com/explosion/spacy-models/releases/download/pt_core_news_md-3.8.0/pt_core_news_md-3.8.0-py3-none-any.whl (42.4 MB)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('pt_core_news_md')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","# Carregando o modelo pre treinado - modelo com relações entre palavras\n","nlp = spacy.load ('pt_core_news_md')\n","\n","# criação de objetos, com suas informações e vetores\n","palavra1 = nlp('rei')\n","palavra2 = nlp('rainha')\n","\n","# Calculo de similaridade dos objetos vetorizadas\n","print (palavra1.similarity(palavra2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VaKxBz4eFKbJ","executionInfo":{"status":"ok","timestamp":1744295100762,"user_tz":180,"elapsed":1582,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"c7f6635e-d925-4737-b5cc-ec4810a0a95e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6001228094100952\n"]}]},{"cell_type":"markdown","source":["## Exemplo 03 - Árvore Sintática"],"metadata":{"id":"8wnbQ3JSF5t7"}},{"cell_type":"code","source":["!python -m spacy download pt_core_news_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6fMhIEKF9T9","executionInfo":{"status":"ok","timestamp":1744297041684,"user_tz":180,"elapsed":8036,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"bc44ab2c-5bcc-4bb6-e5dd-b6902e296f47"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pt-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pt-core-news-sm\n","Successfully installed pt-core-news-sm-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('pt_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import spacy\n","from spacy import displacy\n","# módulo para visualização de dependencias\n","\n","nlp = spacy.load (\"pt_core_news_sm\" )\n","frase = \"O cachorro correu no parque.\"\n","doc = nlp(frase)\n","\n","displacy.render(doc, style='dep', jupyter=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"an_hHN9xKmxc","executionInfo":{"status":"ok","timestamp":1744297047191,"user_tz":180,"elapsed":597,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"353d4a5a-6407-4279-f601-e460667954fc"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"a335c4e63eb7418a8ea275b9b46a2a5b-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">O</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cachorro</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">correu</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">no</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">parque.</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-a335c4e63eb7418a8ea275b9b46a2a5b-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-a335c4e63eb7418a8ea275b9b46a2a5b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-a335c4e63eb7418a8ea275b9b46a2a5b-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-a335c4e63eb7418a8ea275b9b46a2a5b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-a335c4e63eb7418a8ea275b9b46a2a5b-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-a335c4e63eb7418a8ea275b9b46a2a5b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-a335c4e63eb7418a8ea275b9b46a2a5b-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-a335c4e63eb7418a8ea275b9b46a2a5b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Exemplo 04 - Ontologia"],"metadata":{"id":"WQJhssZGNSn2"}},{"cell_type":"code","source":["from owlready2 import *\n","\n","# Criando uma nova ontologia\n","onto = get_ontology (\"http://exemplo.com/minha_ontologia.owl\")\n","\n","with onto:\n","  class Animal(Thing): pass\n","  class Mamifero(Animal): pass\n","  class Cachorro(Mamifero): pass\n","  class Gato(Mamifero): pass\n","\n","onto.save (\"minha_ontologia.owl\")"],"metadata":{"id":"4QrbFXAZNnbo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Estudo de Caso 01 - Aplicação de Análise Semântica em um corpus"],"metadata":{"id":"IFTyBuGVluo8"}},{"cell_type":"code","source":["# Importando as bibliotecas necessárias\n","import spacy\n","import nltk\n","import pandas as pd\n","\n","from nltk.corpus import wordnet as wn\n","# banco de dados léxico - agrupa palavras em conjuntos de sinônimos"],"metadata":{"id":"9adVmNChl3_O","executionInfo":{"status":"ok","timestamp":1744320587254,"user_tz":180,"elapsed":4,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# baixando os corpus e o modelo pré-treinado\n","nltk.download ('wordnet')\n","nltk.download ('omw-1.4')\n","\n","nlp = spacy.load (\"en_core_web_sm\")\n","  # Acessar as funcionalidades como tokenização, análise sintática e vetores de palavras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-rTyyYEmX4n","executionInfo":{"status":"ok","timestamp":1744320589198,"user_tz":180,"elapsed":712,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"0c4bf345-628e-45cf-b9ad-0d5ace26661f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"code","source":["# Texto de estudo de caso\n","text = \"Apple is looking at buying U.K. startup for $1 billion. Steve Jobs founded A\"\n","\n","# 1. Análise Sintática\n","doc = nlp(text)\n","syntactic_data = []\n","\n","for token in doc:\n","  syntactic_data. append ({\n","    \"Token\": token.text,\n","    \"Pos-Tag\": token.pos_,\n","    \"Dependência\": token.dep_,\n","    \"Cabeça da Dep\": token.head.text\n","  })\n","\n","  # Convertendo para DataFrame\n","  df_syntactic = pd.DataFrame(syntactic_data)\n","  print(\"\\nAnálise Sintática:\")\n","  print(df_syntactic)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iPV8LXXknCL3","executionInfo":{"status":"ok","timestamp":1744321075022,"user_tz":180,"elapsed":82,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"c48a4107-3089-4991-a306-8af26bed557f"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Análise Sintática:\n","   Token Pos-Tag Dependência Cabeça da Dep\n","0  Apple   PROPN       nsubj       looking\n","\n","Análise Sintática:\n","   Token Pos-Tag Dependência Cabeça da Dep\n","0  Apple   PROPN       nsubj       looking\n","1     is     AUX         aux       looking\n","\n","Análise Sintática:\n","     Token Pos-Tag Dependência Cabeça da Dep\n","0    Apple   PROPN       nsubj       looking\n","1       is     AUX         aux       looking\n","2  looking    VERB        ROOT       looking\n","\n","Análise Sintática:\n","     Token Pos-Tag Dependência Cabeça da Dep\n","0    Apple   PROPN       nsubj       looking\n","1       is     AUX         aux       looking\n","2  looking    VERB        ROOT       looking\n","3       at     ADP        prep       looking\n","\n","Análise Sintática:\n","     Token Pos-Tag Dependência Cabeça da Dep\n","0    Apple   PROPN       nsubj       looking\n","1       is     AUX         aux       looking\n","2  looking    VERB        ROOT       looking\n","3       at     ADP        prep       looking\n","4   buying    VERB       pcomp            at\n","\n","Análise Sintática:\n","     Token Pos-Tag Dependência Cabeça da Dep\n","0    Apple   PROPN       nsubj       looking\n","1       is     AUX         aux       looking\n","2  looking    VERB        ROOT       looking\n","3       at     ADP        prep       looking\n","4   buying    VERB       pcomp            at\n","5     U.K.   PROPN       nsubj       startup\n","\n","Análise Sintática:\n","     Token Pos-Tag Dependência Cabeça da Dep\n","0    Apple   PROPN       nsubj       looking\n","1       is     AUX         aux       looking\n","2  looking    VERB        ROOT       looking\n","3       at     ADP        prep       looking\n","4   buying    VERB       pcomp            at\n","5     U.K.   PROPN       nsubj       startup\n","6  startup    VERB       ccomp        buying\n","\n","Análise Sintática:\n","     Token Pos-Tag Dependência Cabeça da Dep\n","0    Apple   PROPN       nsubj       looking\n","1       is     AUX         aux       looking\n","2  looking    VERB        ROOT       looking\n","3       at     ADP        prep       looking\n","4   buying    VERB       pcomp            at\n","5     U.K.   PROPN       nsubj       startup\n","6  startup    VERB       ccomp        buying\n","7      for     ADP        prep       startup\n","\n","Análise Sintática:\n","     Token Pos-Tag Dependência Cabeça da Dep\n","0    Apple   PROPN       nsubj       looking\n","1       is     AUX         aux       looking\n","2  looking    VERB        ROOT       looking\n","3       at     ADP        prep       looking\n","4   buying    VERB       pcomp            at\n","5     U.K.   PROPN       nsubj       startup\n","6  startup    VERB       ccomp        buying\n","7      for     ADP        prep       startup\n","8        $     SYM    quantmod       billion\n","\n","Análise Sintática:\n","     Token Pos-Tag Dependência Cabeça da Dep\n","0    Apple   PROPN       nsubj       looking\n","1       is     AUX         aux       looking\n","2  looking    VERB        ROOT       looking\n","3       at     ADP        prep       looking\n","4   buying    VERB       pcomp            at\n","5     U.K.   PROPN       nsubj       startup\n","6  startup    VERB       ccomp        buying\n","7      for     ADP        prep       startup\n","8        $     SYM    quantmod       billion\n","9        1     NUM    compound       billion\n","\n","Análise Sintática:\n","      Token Pos-Tag Dependência Cabeça da Dep\n","0     Apple   PROPN       nsubj       looking\n","1        is     AUX         aux       looking\n","2   looking    VERB        ROOT       looking\n","3        at     ADP        prep       looking\n","4    buying    VERB       pcomp            at\n","5      U.K.   PROPN       nsubj       startup\n","6   startup    VERB       ccomp        buying\n","7       for     ADP        prep       startup\n","8         $     SYM    quantmod       billion\n","9         1     NUM    compound       billion\n","10  billion     NUM        pobj           for\n","\n","Análise Sintática:\n","      Token Pos-Tag Dependência Cabeça da Dep\n","0     Apple   PROPN       nsubj       looking\n","1        is     AUX         aux       looking\n","2   looking    VERB        ROOT       looking\n","3        at     ADP        prep       looking\n","4    buying    VERB       pcomp            at\n","5      U.K.   PROPN       nsubj       startup\n","6   startup    VERB       ccomp        buying\n","7       for     ADP        prep       startup\n","8         $     SYM    quantmod       billion\n","9         1     NUM    compound       billion\n","10  billion     NUM        pobj           for\n","11        .   PUNCT       punct       looking\n","\n","Análise Sintática:\n","      Token Pos-Tag Dependência Cabeça da Dep\n","0     Apple   PROPN       nsubj       looking\n","1        is     AUX         aux       looking\n","2   looking    VERB        ROOT       looking\n","3        at     ADP        prep       looking\n","4    buying    VERB       pcomp            at\n","5      U.K.   PROPN       nsubj       startup\n","6   startup    VERB       ccomp        buying\n","7       for     ADP        prep       startup\n","8         $     SYM    quantmod       billion\n","9         1     NUM    compound       billion\n","10  billion     NUM        pobj           for\n","11        .   PUNCT       punct       looking\n","12    Steve   PROPN    compound          Jobs\n","\n","Análise Sintática:\n","      Token Pos-Tag Dependência Cabeça da Dep\n","0     Apple   PROPN       nsubj       looking\n","1        is     AUX         aux       looking\n","2   looking    VERB        ROOT       looking\n","3        at     ADP        prep       looking\n","4    buying    VERB       pcomp            at\n","5      U.K.   PROPN       nsubj       startup\n","6   startup    VERB       ccomp        buying\n","7       for     ADP        prep       startup\n","8         $     SYM    quantmod       billion\n","9         1     NUM    compound       billion\n","10  billion     NUM        pobj           for\n","11        .   PUNCT       punct       looking\n","12    Steve   PROPN    compound          Jobs\n","13     Jobs   PROPN       nsubj       founded\n","\n","Análise Sintática:\n","      Token Pos-Tag Dependência Cabeça da Dep\n","0     Apple   PROPN       nsubj       looking\n","1        is     AUX         aux       looking\n","2   looking    VERB        ROOT       looking\n","3        at     ADP        prep       looking\n","4    buying    VERB       pcomp            at\n","5      U.K.   PROPN       nsubj       startup\n","6   startup    VERB       ccomp        buying\n","7       for     ADP        prep       startup\n","8         $     SYM    quantmod       billion\n","9         1     NUM    compound       billion\n","10  billion     NUM        pobj           for\n","11        .   PUNCT       punct       looking\n","12    Steve   PROPN    compound          Jobs\n","13     Jobs   PROPN       nsubj       founded\n","14  founded    VERB        ROOT       founded\n","\n","Análise Sintática:\n","      Token Pos-Tag Dependência Cabeça da Dep\n","0     Apple   PROPN       nsubj       looking\n","1        is     AUX         aux       looking\n","2   looking    VERB        ROOT       looking\n","3        at     ADP        prep       looking\n","4    buying    VERB       pcomp            at\n","5      U.K.   PROPN       nsubj       startup\n","6   startup    VERB       ccomp        buying\n","7       for     ADP        prep       startup\n","8         $     SYM    quantmod       billion\n","9         1     NUM    compound       billion\n","10  billion     NUM        pobj           for\n","11        .   PUNCT       punct       looking\n","12    Steve   PROPN    compound          Jobs\n","13     Jobs   PROPN       nsubj       founded\n","14  founded    VERB        ROOT       founded\n","15        A    PRON        dobj       founded\n"]}]},{"cell_type":"code","source":["# 2. Reconhecimento de Entidades Nomeadas (NER)\n","entities_data = []\n","\n","for ent in doc.ents:\n","  entities_data.append ({\n","    \"Entidade\": ent.text,\n","    \"Tipo\": ent. label_\n","})\n","\n","# Convertendo para DataFrame\n","df_entities = pd.DataFrame(entities_data)\n","print(\"\\n Reconhecimento de Entidades:\")\n","print(df_entities)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XzxJYTt8pC7g","executionInfo":{"status":"ok","timestamp":1744322949028,"user_tz":180,"elapsed":13,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"7d36faae-41f4-4674-d4b0-bb2114a61c5b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Reconhecimento de Entidades:\n","     Entidade    Tipo\n","0       Apple     ORG\n","1        U.K.     GPE\n","2  $1 billion   MONEY\n","3  Steve Jobs  PERSON\n"]}]},{"cell_type":"code","source":["# 3. Análise Semântica com WordNet\n","semantic_data = []\n","\n","for token in doc:\n","  synsets = wn.synsets(token.text)\n","  if synsets:\n","    semantic_data.append({\n","      \"Palavra\": token.text,\n","      \"Significado\": synsets[0].definition(),\n","      \"Exemplo\": synsets[0].examples()\n","    })\n","# Convertendo para DataFrame\n","df_semantic = pd.DataFrame(semantic_data)\n","print(\"\\n Análise Semântica:\")\n","print(df_semantic)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RPNWr_xwGeZ","executionInfo":{"status":"ok","timestamp":1744323224029,"user_tz":180,"elapsed":4089,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"532b618d-0874-4b1b-8623-6d6b3539c5b2"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Análise Semântica:\n","    Palavra                                        Significado  \\\n","0     Apple  fruit with red or yellow or green skin and swe...   \n","1        is  have the quality of being; (copula, used with ...   \n","2   looking  the act of directing the eyes toward something...   \n","3        at  a highly unstable radioactive element (the hea...   \n","4    buying                                  the act of buying   \n","5      U.K.  a monarchy in northwestern Europe occupying mo...   \n","6   startup                    the act of setting in operation   \n","7         1  the smallest whole number or a numeral represe...   \n","8   billion  the number that is represented as a one follow...   \n","9      Jobs  the principal activity in your life that you d...   \n","10  founded                                    set up or found   \n","11        A  a metric unit of length equal to one ten billi...   \n","\n","                                              Exemplo  \n","0                                                  []  \n","1           [John is rich, This is not a good answer]  \n","2   [he went out to have a look, his look was fixe...  \n","3                                                  []  \n","4   [buying and selling fill their days, shrewd pu...  \n","5                                                  []  \n","6     [repeated shutdowns and startups are expensive]  \n","7   [he has the one but will need a two and three ...  \n","8                                                  []  \n","9                   [he's not in my line of business]  \n","10                    [She set up a literacy program]  \n","11                                                 []  \n"]}]}]}
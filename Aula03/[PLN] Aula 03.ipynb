{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEXtptudsME0XVkoxm55Zs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MRRmTRByu5gR"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Aula 03 - Processamento de Texto e Pré-processamento de Dados"],"metadata":{"id":"XHuzRSajvUzq"}},{"cell_type":"markdown","source":["## 1. Normalização de texto e Remoção de Ruído"],"metadata":{"id":"yFWgxuizR4cn"}},{"cell_type":"code","source":["# importa a biblioteca para trabalhar com expressões regulares\n","import re\n","\n","original = \"Olá!!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos #especiais e LETRAS maiúsculas.\"\n","\n","texto_limpo = re.sub(r'[^A-Za-zÀ-ÿ\\s]', '', original)\n","\n","texto_normalizado = texto_limpo.lower()\n","\n","print(f'Texto original: {original}')\n","print(f'\\nTexto limpo: {texto_limpo}')\n","print(f'\\nTexto normalizado: {texto_normalizado}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqIRYZh3R_uD","executionInfo":{"status":"ok","timestamp":1744063851452,"user_tz":180,"elapsed":14,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"ddb6d798-6eb8-4558-e504-eb4b82c4cef5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Texto original: Olá!!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos especiais e LETRAS maiúsculas.\n","\n","Texto limpo: Olá Este é um exemplo de texto com várias PONTUAÇÕES símbolos especiais e LETRAS maiúsculas\n","\n","Texto normalizado: olá este é um exemplo de texto com várias pontuações símbolos especiais e letras maiúsculas\n"]}]},{"cell_type":"markdown","source":["## 2. Tokenização  \n","Tokenização é dividir o texto em unidades menores (tokens), que geralmente são palavras ou pontuações."],"metadata":{"id":"aPHgqQCyT3D6"}},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('punkt_tab')\n","\n","tokens = word_tokenize(texto_normalizado)\n","\n","print(f'Texto original: {original}')\n","print(f'\\nTexto limpo: {texto_limpo}')\n","print(f'\\nTexto normalizado: {texto_normalizado}')\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-KSvefkT7J9","executionInfo":{"status":"ok","timestamp":1744064415210,"user_tz":180,"elapsed":52,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"8df67f2b-9e2c-4bfd-d115-8d0bb83e5fe5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Texto original: Olá!!! Este é um exemplo de texto, com várias PONTUAÇÕES, símbolos especiais e LETRAS maiúsculas.\n","\n","Texto limpo: Olá Este é um exemplo de texto com várias PONTUAÇÕES símbolos especiais e LETRAS maiúsculas\n","\n","Texto normalizado: olá este é um exemplo de texto com várias pontuações símbolos especiais e letras maiúsculas\n","['olá', 'este', 'é', 'um', 'exemplo', 'de', 'texto', 'com', 'várias', 'pontuações', 'símbolos', 'especiais', 'e', 'letras', 'maiúsculas']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## 3. Remoção de Stopwords  \n","Stopwords são palavras de pouco valor semântico (como 'de', 'a', 'o') que podem ser removidas para simplificar o texto."],"metadata":{"id":"GNXKAH1pUxwR"}},{"cell_type":"markdown","source":[],"metadata":{"id":"6phb34JDWv56"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","\n","stopwords_pt = set(stopwords.words('portuguese'))\n","tokens_sem_stopwords = [palavra for palavra in tokens if palavra.lower() not in stopwords_pt]\n","print(f\"Tokens extraídos: {tokens}\" + f\"\\nquantidade de tokens: {len(tokens)}\")\n","print(f\"Tokens sem stopwords: {tokens_sem_stopwords}\" + f\"\\nquantidade de tokens sem stopwords: {len(tokens_sem_stopwords)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vl2RIOYyUyzZ","executionInfo":{"status":"ok","timestamp":1744064975849,"user_tz":180,"elapsed":14,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"841c6546-bab9-4a4b-b178-bad63b965e63"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens extraídos: ['olá', 'este', 'é', 'um', 'exemplo', 'de', 'texto', 'com', 'várias', 'pontuações', 'símbolos', 'especiais', 'e', 'letras', 'maiúsculas']\n","quantidade de tokens: 15\n","Tokens sem stopwords: ['olá', 'exemplo', 'texto', 'várias', 'pontuações', 'símbolos', 'especiais', 'letras', 'maiúsculas']\n","quantidade de tokens sem stopwords: 9\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## 4. Stemming e Lemalização\n","\n","\n","*   Stemming reduz as palavras às suas raízes (ou radicais);\n","*   Lematização normaliza as palavras para suas formas base, levando em conta contexto e gramática.\n","\n"],"metadata":{"id":"4RqgiyAYWxjv"}},{"cell_type":"code","source":["from nltk.stem import RSLPStemmer\n","\n","nltk.download('rslp')\n","\n","stemmer = RSLPStemmer()\n","stemming = [stemmer.stem(palavra) for palavra in tokens_sem_stopwords]\n","print(\"Tokens:\", tokens_sem_stopwords)\n","print(\"Tokens radicais:\", stemming)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l9nEA3UhYCxJ","executionInfo":{"status":"ok","timestamp":1744065233857,"user_tz":180,"elapsed":14,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"b14b240b-6b21-494f-d152-9980a9a46029"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens: ['olá', 'exemplo', 'texto', 'várias', 'pontuações', 'símbolos', 'especiais', 'letras', 'maiúsculas']\n","Tokens radicais: ['olá', 'exempl', 'text', 'vár', 'pontu', 'símbol', 'espec', 'letr', 'maiúscul']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package rslp to /root/nltk_data...\n","[nltk_data]   Package rslp is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## 5. Exemplo 01 - Pré-Processamento Completo"],"metadata":{"id":"HrFCirK8ZRKY"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","import re\n","\n","# Download dos recursos do NLTK (se necessário)\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Texto de exemplo\n","texto = input(\"Insira um texto que seja coerente, podendo ter símbolos: \")\n","\n","# Limpeza de ruídos e normalização\n","texto_limpo = re.sub(r'[^A-Za-zÀ-ÿ\\s]', '', texto)\n","texto_normalizado = texto_limpo.lower()\n","\n","# Tokenização\n","tokens = nltk.word_tokenize(texto_normalizado)\n","\n","# Remoção de stopwords\n","stop_words = set(stopwords.words('portuguese'))\n","palavras_filtradas_ex = [palavra for palavra in tokens if palavra not in stop_words]\n","\n","# Stemming\n","stemmer = RSLPStemmer()\n","palavras_stemizadas = [stemmer.stem(palavra) for palavra in palavras_filtradas_ex]\n","\n","# Impressão do resultado final\n","print(palavras_stemizadas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGq-ZN8ZZQZa","executionInfo":{"status":"ok","timestamp":1744067716758,"user_tz":180,"elapsed":2492,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"f1ce1eec-a1e9-41b1-8109-235843632bef"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Insira um texto que seja coerente, podendo ter símbolos: pontuação como pontos\n","['pontu', 'pont']\n"]}]},{"cell_type":"markdown","source":["## Exemplo 02 - Estrutura de Pré-processamento de texto\n"],"metadata":{"id":"YdNIlpGEjuY1"}},{"cell_type":"code","source":["!pip install spacy\n","!python -m spacy download pt_core_news_sm\n","import re\n","import spacy\n","import nltk\n","from nltk.corpus import stopwords\n","import string"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqAXDi4Qj7gw","executionInfo":{"status":"ok","timestamp":1744068207503,"user_tz":180,"elapsed":13869,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"dfccef62-f1ac-49af-903a-e77a424d819b"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n","Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Collecting pt-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('pt_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"markdown","source":["## Exemplo 03 - O modelo pré-treinado"],"metadata":{"id":"ZrhUdWvyi-W8"}},{"cell_type":"code","source":["import spacy\n","\n","# Carregar,o modelo para português\n","nlp = spacy. load(\"pt_core_news_sm\")\n","\n","# Processar um texto em português\n","textoRecebido = input(\"Digite um texto para ser analisado: \")\n","doc = nlp(textoRecebido)\n","\n","print( '\\nAnálise gramatical das palavras:')\n","for token in doc:\n","  print(f\"Palavra: {token.text}, Classe: {token.pos_}\")\n","\n","print (\"\\nAnalise de Dependências:\")\n","for token in doc:\n","  print(f\"Palavra: (token.text), Depende de: {token.head.text}\")\n","\n","# Visualizar a árvore graficamente (opcional)\n","from spacy import displacy\n","displacy.render(doc, style=\"dep\", jupyter=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":698},"id":"77RUIOdwjE2V","executionInfo":{"status":"ok","timestamp":1744068227371,"user_tz":180,"elapsed":14289,"user":{"displayName":"Junior Silva","userId":"13201648918475997455"}},"outputId":"d089d484-5997-443d-d64b-e6dd41ec617a"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Digite um texto para ser analisado: Olá, Como vai? Tudo bem?\n","\n","Análise gramatical das palavras:\n","Palavra: Olá, Classe: PROPN\n","Palavra: ,, Classe: PUNCT\n","Palavra: Como, Classe: ADV\n","Palavra: vai, Classe: AUX\n","Palavra: ?, Classe: PUNCT\n","Palavra: Tudo, Classe: PRON\n","Palavra: bem, Classe: ADV\n","Palavra: ?, Classe: PUNCT\n","\n","Analise de Dependências:\n","Palavra: (token.text), Depende de: Olá\n","Palavra: (token.text), Depende de: Olá\n","Palavra: (token.text), Depende de: vai\n","Palavra: (token.text), Depende de: Olá\n","Palavra: (token.text), Depende de: Olá\n","Palavra: (token.text), Depende de: Tudo\n","Palavra: (token.text), Depende de: Tudo\n","Palavra: (token.text), Depende de: Tudo\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"53cfa94e0df3412882c1c71fb53d93ca-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Olá,</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Como</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADV</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">vai?</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Tudo</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PRON</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">bem?</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADV</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-53cfa94e0df3412882c1c71fb53d93ca-0-0\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-53cfa94e0df3412882c1c71fb53d93ca-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-53cfa94e0df3412882c1c71fb53d93ca-0-1\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-53cfa94e0df3412882c1c71fb53d93ca-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl:relcl</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M400.0,179.0 L408.0,167.0 392.0,167.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-53cfa94e0df3412882c1c71fb53d93ca-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-53cfa94e0df3412882c1c71fb53d93ca-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"]},"metadata":{}}]}]}